{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with columns\n",
    "data = {\n",
    "    'Link': [],\n",
    "    'Job title': [],\n",
    "    'Company name': [],\n",
    "    'Location': [],\n",
    "    'Salary':[],\n",
    "    'Description': [],\n",
    "    'Seniority level': [],\n",
    "    'Employment type': [],\n",
    "    'Job function': [],\n",
    "    'Industries': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsList = [\"Shop Manager\",\n",
    "\"Artificial Intelligence Engineer\",\n",
    "\"Restaurant Specialist\",\n",
    "\"Marketer\",\n",
    "\"Dietary Aide\",\n",
    "\"Development Team Lead\",\n",
    "\"Beauty Advisor\",\n",
    "\"Nursing Manager\",\n",
    "\"Receptionist\",\n",
    "\"SAP ABAP Developer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobsList:\n",
    "    for num in range(25, 1001, 25):\n",
    "        print(f\"request for {num}\")\n",
    "        response = requests.get(f'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/{job}-jobs?position=1&pageNum=0&start={num}')\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        length_results = len(soup.find_all('li'))\n",
    "        for number, li in enumerate(soup.find_all('li')):\n",
    "            print(f\"result {number}/{length_results}\")\n",
    "            try:\n",
    "                salary = li.find('span', class_='job-search-card__salary-info').text.strip()\n",
    "            except:\n",
    "                salary = 'not found'\n",
    "            try:\n",
    "                link = li.find('a', class_='base-card__full-link').get('href')\n",
    "            except:\n",
    "                continue\n",
    "            print(link)\n",
    "\n",
    "            soup2 = BeautifulSoup(requests.get(link).text, 'html.parser')\n",
    "            crits = {}\n",
    "            try:\n",
    "                for li in soup2.find('ul', class_='description__job-criteria-list').find_all('li'):\n",
    "                    crits[li.find('h3').text.strip()] = li.find('span').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            print(crits.keys())\n",
    "\n",
    "            data['Link'].append(link)\n",
    "            try:\n",
    "                data['Salary'].append(salary)\n",
    "            except:\n",
    "                data['Salary'].append(None)\n",
    "\n",
    "            try:\n",
    "                data['Job title'].append(soup2.find('h1', class_='topcard__title').text.strip())\n",
    "            except:\n",
    "                data['Job title'].append('not Found')\n",
    "\n",
    "            try:\n",
    "                data['Company name'].append(soup2.find('a', class_='topcard__org-name-link topcard__flavor--black-link').text.strip())\n",
    "            except:\n",
    "                data['Company name'].append('not Found')\n",
    "\n",
    "            try:\n",
    "                data['Location'].append(soup2.find('span', class_='topcard__flavor topcard__flavor--bullet').text.strip())\n",
    "            except:\n",
    "                data['Location'].append('not Found')\n",
    "                \n",
    "            try:\n",
    "                data['Description'].append(soup2.find('div', class_='show-more-less-html__markup').text.strip())\n",
    "            except:\n",
    "                data['Description'].append('not Found')\n",
    "                \n",
    "\n",
    "            data['Seniority level'].append(crits['Seniority level'] if 'Seniority level' in crits.keys() else None)\n",
    "            data['Employment type'].append(crits['Employment type'] if 'Employment type' in crits.keys() else None)\n",
    "            data['Job function'].append(crits['Job function'] if 'Job function' in crits.keys() else None)\n",
    "            data['Industries'].append(crits['Industries'] if 'Industries' in crits.keys() else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('hugeData.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
